@TheoSteiner 0:00
UITのテオです。

@TheoSteiner 0:11
ユーザーインターフェースとテクノロジーを愛する開発者のためのウィークリーポッドキャスト UIT INSIDE、今週も始めたいと思います。

@TheoSteiner 0:20
今回はGoogle I/O 2025年をテーマに話していきます。

@TheoSteiner 0:25
浜田さん、津村さん、森本さん、本日はよろしくお願いします。

@mahamada 0:30
よろしくお願いします。

@TheoSteiner 0:32
今日はなんとGoogle I/Oの現地マウンテンビューからエピソードを収録します。
一緒にGoogle I/Oに来ているLINEヤフーのフロントエンドの3人が参加してくれて嬉しいです。
一人一人自己紹介していただけますか？

@mahamada 0:52
トップページと全社のフロントエンドを統括している浜田と言います。よろしくお願いします。

@l1lhu1hu1 0:57
Yahoo!知恵袋のフロントエンドを担当している津村です。よろしくお願いします。

@basara669 1:02
知恵袋の森本です。お願いします。

@TheoSteiner 1:06
Google I/OはGoogle社の年に1回あるすごく大きなイベントです。
きっと皆さんもニュースやYouTubeでキーノートを見たと思いますが、
今回は現地参加できたので、軽く感想を皆さんにぜひ聞きたいなと思います。
一番印象に残ったアナウンスやニュースは何ですか？

@TheoSteiner 1:36
浜田さん、何がありましたか？

@mahamada 1:39
そうですね、たくさんありました。もちろんGeminiの新しいバージョンも使ってみたいと思っていますが、
私が一番気になったのは検索に新しく入ったAIモードですね。
これまで検索はワードを入力して検索結果を自分で選んで見るのが一般的でしたが、
ついに待望の、検索したものをそのままAIが答えるというモードが入りました。

@mahamada 2:10
Googleで検索するとタブが出てくると思うんですけど、
例えば画像やグルメなどのタブを選択することでジャンルを切り替えられますが、
その一つのジャンルの中にAIモードが入る形で統合されたのが新しい機能だったなと思います。

@TheoSteiner 2:29
検索のタブが増えることはなかなかないので、結構大きなアナウンスでしたね。
個人的にはGemini Live、Googleが今開発中のAIエージェントが印象に残っています。
実際にGeminiのアプリで使ってみることができて、普通に人と話しているようにAIエージェントと会話でき、
いろんなことを解説してもらったり、注文やホテルの予約も任せられそうで、これはすごいなと思いました。

@TheoSteiner 3:10
森本さん的に一番印象に残ったものは何ですか？

@basara669 3:13
やっぱりAndroid XRですね。久々のハードウェアアナウンスがありました。
Google I/Oでハードウェアの発表があったのと、年内発売というのも大きかったです。
ローンチはUSだけだと思いますが、発売日まで出ているのも熱いなと思いました。

@basara669 3:38
今回はAndroid XRでヘッドセット型のMUHANとグラス型の2つが発表されました。
MUHANもグラス型も両方試せるブースがありましたが、MUHANは人気で今回参加したメンバーは誰も体験できなかったですね。
予約がすごくて、初日の午前中ぐらいに全枠埋まった感じでした。
ブース自体も遠目からしか見えず、写真を撮ろうとするとNO!と怒られる感じでした。
サイズはVision Proぐらい大きくて、つけてる人も重そうで、ヘッドセット型は大変そうだなと感じました。

@basara669 4:41
グラス型も話したいんですが、MetaやRabianのものと似ていて、
スピーカーとマイク、カメラがついていて、小さなディスプレイもついています。
よりリッチな体験を提供できる感じで、Googleマップの方向表示や、下を向くと矢印が出て道案内してくれる体験ができました。
Geminiの機能も使え、例えば「どこにカップを置いた？」などの質問にも答えられるようになっていました。
体験は90秒ほどでしたが、かなり完成度が高く、年内発売というだけあって良いレベルでした。

@basara669 6:00
今回ジェントルモンスターとのコラボでデザインも気になりますし、
僕のような視力が悪い人向けには、プロトタイプでは後ろに矯正用グラスを入れて2枚重ねで使う形でした。
実際販売される時にどうなるのか気になります。
視力が悪い人がそのままかけるとボヤけてしまうので、矯正必須なのかなと気になります。

@TheoSteiner 6:55
今回のI/Oはプロダクトのアナウンスが多かったですね。
昔はピュアな開発者向けカンファレンスでしたが、どんどんプロダクトアナウンスが増えています。
でも僕たちは開発者として参加したので、一番気になったのはWeb開発に関わるアナウンスですね。
これからメジャーなWebのアナウンスについて一つずつ触れていきたいと思います。

@TheoSteiner 7:28
まずビルトインAI、Chromeに含まれるAIモデルですね。
これは前回のI/Oで発表されていて、今後Chromeでモデルが提供され、
Web JavaScriptのAPIからモデルが呼び出せるようになります。
去年のI/Oで発表されましたが、APIにいくつか変更が加わりました。

@TheoSteiner 8:01
津村さん、その説明お願いしてもいいですか？

@l1lhu1hu1 8:05
今回マルチモーダルなプロンプトAPIが発表されました。
画像や音声を入力にできるようになり、例えば音声や画像から説明テキストを出したり、
アクセシビリティ用途やプルーフリーダーとしても使えそうです。
デモでは間違い部分にハイライトを出すなどもやっていて、夢があるなと感じました。

@mahamada 8:39
クライアントサイドAIだと本当にクライアントだけで完結しますが、
今回のマルチモーダルAPIでは画像をクライアントサイドで扱えます。
サーバーサイドで画像連携する場合は大量のデータ送信が必要ですが、
今回はクライアントのGPUだけで処理できるのがポイントです。

@l1lhu1hu1 9:08
自分もサマライザーやリライターを使っていましたが、
新しいマルチモーダルAPIではテキスト以外も扱えるので、使いどころが増えそうです。

@mahamada 9:25
使いどころは少し難しいですが、通信をしない特徴に向く用途には向いていると思います。

@TheoSteiner 9:36
ちなみにそのAIを使うにはユーザーに何が必要ですか？
かなり新しいChromeブラウザが必要ですか？

@mahamada 9:48
そうですね、まだパブリックには公開されておらず、テスト段階の機能です。
より新しい機能はEarly Access Program登録が必要です。

@mahamada 10:07
もし使えない場合は、今回新しく発表されたハイブリッドAPIがあり、
SafariなどではFirebaseにフォールバックする機能が追加されました。
FirebaseのAPIキー設定でGoogleがホスティングするサーバー側でモデルを呼び出せます。
これでSafariユーザーでもポリフィル的に使えます。

@TheoSteiner 10:44
ChromeのUIで新しいUIパターンを実装できる機能も追加されました。
一番注目されたのはCSSカルーセルの作り方です。
HTMLとCSSだけでカルーセルを実装でき、UIパターンとしてカルーセルを使うことが多いので、非常に便利です。
つい最近プロダクトにカルーセルを導入したのですが、何百行ものJavaScriptが必要でした。
CSSとHTMLだけで完結できるのは大きいです。

@mahamada 11:43
Webのエコシステムを考える人たちは、Webのユースケースを大切にしてWeb標準に落とすことを常にやっています。
今回ついにカルーセルが登場し、今自分はパフォーマンス改善を担当していますが、
カルーセルの実装は複雑でパフォーマンスやバグの温床でした。
CSSカルーセルならJavaScriptゼロで実装でき、問題も減り、パフォーマンス改善もしやすいです。

@TheoSteiner 12:37
実は発表の後にSara Soueidanさんのブログでアクセシビリティ課題がまだあることを知りました。
今後ブラウザのサポートが進み、アクセシビリティも改善されれば本当に期待できる機能です。

@TheoSteiner 13:35
開発ツールも大きく進化しました。
Chrome DevToolsにAIアシスタントが搭載され、簡単なコマンドや修正内容を入力するとAIがコードを修正し、適用ボタンでプロダクションに反映できます。
特に経験の浅い開発者にもバグ修正の助けになる機能です。

@mahamada 15:18
パフォーマンスタブもAIの力が入り、コアメトリクスや改善提案をAIが表示。ASK AIもできるようになりました。
ただしAIアシストにはGoogleサーバーのGemini Flashを使うため、コードがサーバーに送信される点に注意が必要です。
エンタープライズChromeでは管理者が設定でき、サーバー側で保存されない約束になっています。

@TheoSteiner 16:55
ベースラインというWebの新しい概念にも注目です。
MDNでAPIを確認するとベースラインのロゴが表示され、Newly Available, Limited Available, Widely Availableの3種があります。
ESLintのプラグインも発表され、VS CodeなどのエディタでAPIの利用可否を即時チェック可能になりました。
ターゲット年次も指定でき、例えばベースライン2024年をターゲットに設定できます。

@TheoSteiner 20:54
最後にクレデンシャルマネージャーという認証管理APIがChromeに追加されました。
パスキーやパスワード、FedCMなどを一元管理でき、自動パスワード更新や入力も可能。
Well-known Change Passwordパスを用意すると、パスワード漏洩時にAIが自動でパスワードを変更してくれる機能も追加されました。

@TheoSteiner 22:27
Webサイトのログイン方法が多様化する中、Credential Managerによって一体感のあるUIが実現されました。
パスワードマネージャー専用属性も増え、オートコンプリートやオートフィルもより強化されています。

@TheoSteiner 24:25
今回も盛りだくさんの内容でしたが、すべて確認できる公式リンクをショーノートに貼っておきます。

@TheoSteiner 24:42
今回はGoogle I/Oについて話してきました。
LINEヤフーのフロントエンド開発組織UITでは、このようなフロントエンドに関する議論やキャッチアップ、コンテンツ開発を日々行っています。
過去のエピソードでは社内の学習企画から始まったコンテンツも多くありますので、今後も発信していければと思います。

@TheoSteiner 25:04
今回はGoogle I/Oの現地から発信しました。浜田さん、津村さん、森本さんありがとうございました。

@mahamada 25:13
ありがとうございました。

@l1lhu1hu1 25:13
ありがとうございました。

@basara669 25:13
ありがとうございました。
